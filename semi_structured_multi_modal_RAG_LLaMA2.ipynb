{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langchain langchain-chroma \"unstructured[all-docs]\" pydantic lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partitioning Source Files using Unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"
     ]
    }
   ],
   "source": [
    "from typing import Any\n",
    "from pydantic import BaseModel\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "# Path to save images\n",
    "path = \"./figures/temp/\"\n",
    "\n",
    "# Get elements\n",
    "raw_pdf_elements = partition_pdf(\n",
    "    filename='./data/shortExample2_Nutrition_20Pgs.pdf',\n",
    "    languages=['eng'],\n",
    "    strategy='hi_res',\n",
    "    # Using pdf format to find embedded image blocks\n",
    "    extract_images_in_pdf=True,\n",
    "    # Use layout model (YOLOX) to get bounding boxes (for tables) and find titles\n",
    "    # Titles are any sub-section of the document\n",
    "    infer_table_structure=True,\n",
    "    # Post processing to aggregate text once we have the title\n",
    " \n",
    "    # Chunking params to aggregate text blocks\n",
    "    # Attempt to create a new chunk 3800 chars\n",
    "    # Attempt to keep chunks > 2000 chars\n",
    "    # Hard max on chunks   \n",
    "\n",
    "\n",
    "    # --- Unstructure can't do semantic chunking, it only does fixed sized and by_title. \n",
    "    # --- I will use langChain semantic chunker for that.\n",
    "    \n",
    "    # ----If letting it to do chunking---\n",
    "    # chunking_strategy=\"by_title\",\n",
    "    # max_characters=4000,\n",
    "    # new_after_n_chars=3800,\n",
    "    # combine_text_under_n_chars=2000,\n",
    "    # ------------------------------\n",
    "\n",
    "    image_output_dir_path=path,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"<class 'unstructured.documents.elements.Header'>\": 22,\n",
       " \"<class 'unstructured.documents.elements.Title'>\": 61,\n",
       " \"<class 'unstructured.documents.elements.NarrativeText'>\": 158,\n",
       " \"<class 'unstructured.documents.elements.Footer'>\": 1,\n",
       " \"<class 'unstructured.documents.elements.Text'>\": 27,\n",
       " \"<class 'unstructured.documents.elements.Image'>\": 21,\n",
       " \"<class 'unstructured.documents.elements.FigureCaption'>\": 3,\n",
       " \"<class 'unstructured.documents.elements.Table'>\": 4,\n",
       " \"<class 'unstructured.documents.elements.ListItem'>\": 19}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary to store counts of each type\n",
    "category_counts = {}\n",
    "\n",
    "for element in raw_pdf_elements:\n",
    "    category = str(type(element))\n",
    "    if category in category_counts:\n",
    "        category_counts[category] += 1\n",
    "    else:\n",
    "        category_counts[category] = 1\n",
    "\n",
    "# Unique_categories will have unique elements\n",
    "# TableChunk if Table > max chars set above\n",
    "unique_categories = set(category_counts.keys())\n",
    "category_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Partitioned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tables extracted: 4\n",
      "Number of text elements for semantic chunking: 49\n",
      "Number of images detected: 21\n",
      "Number of headers: 22\n",
      "Number of titles: 61\n",
      "Number of footers (ignored for RAG): 1\n",
      "Number of figure captions: 3\n",
      "Number of list items: 19\n"
     ]
    }
   ],
   "source": [
    "from typing import Any\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Re-defining Element class just in case, ensure it's here\n",
    "class Element(BaseModel):\n",
    "    type: str\n",
    "    text: Any\n",
    "\n",
    "# Initialize lists for categorized elements\n",
    "text_for_semantic_chunking = []\n",
    "tables_raw = []\n",
    "images_raw = []\n",
    "headers_raw = []\n",
    "titles_raw = []\n",
    "footers_raw = []\n",
    "figure_captions_raw = []\n",
    "list_items_raw = []\n",
    "\n",
    "# Variables to build coherent text blocks\n",
    "current_text_block = \"\"\n",
    "current_context_prefix = \"\"\n",
    "min_meaningful_text_length = 50 # Minimum length for a text block to be considered meaningful\n",
    "\n",
    "# Helper to finalize and append current text block - defined globally\n",
    "def finalize_text_block():\n",
    "    global current_text_block # Use 'global' to modify the top-level variable\n",
    "    global current_context_prefix # Use 'global' to modify the top-level variable\n",
    "    if current_text_block.strip() and len(current_text_block.strip()) >= min_meaningful_text_length:\n",
    "        text_for_semantic_chunking.append(Element(type=\"text\", text=current_text_block.strip()))\n",
    "    current_text_block = \"\" # Reset for next block\n",
    "\n",
    "for i, element in enumerate(raw_pdf_elements):\n",
    "    element_type_str = str(type(element))\n",
    "    element_text = str(element).strip() # Get text and strip whitespace\n",
    "\n",
    "    if \"unstructured.documents.elements.Header\" in element_type_str:\n",
    "        finalize_text_block() # Finalize any pending text block\n",
    "        current_context_prefix = element_text + \" \" # Set new context\n",
    "        headers_raw.append(Element(type=\"header\", text=element_text))\n",
    "    elif \"unstructured.documents.elements.Title\" in element_type_str:\n",
    "        finalize_text_block() # Finalize any pending text block\n",
    "        current_context_prefix = element_text + \" \" # Set new context\n",
    "        titles_raw.append(Element(type=\"title\", text=element_text))\n",
    "    elif \"unstructured.documents.elements.NarrativeText\" in element_type_str or \\\n",
    "         \"unstructured.documents.elements.ListItem\" in element_type_str or \\\n",
    "         \"unstructured.documents.elements.Text\" in element_type_str:\n",
    "        # Check if it's a short, likely non-informative text element (like a page number or \"--o--\")\n",
    "        if len(element_text) < 5 and not any(char.isalpha() for char in element_text):\n",
    "            # If it's very short and contains no letters, skip it (e.g., \"18\", \"--o--\")\n",
    "            continue\n",
    "\n",
    "        # Add context prefix if it's the start of a new narrative block\n",
    "        if not current_text_block and current_context_prefix:\n",
    "            current_text_block += current_context_prefix\n",
    "            current_context_prefix = \"\" # Use context once per block\n",
    "\n",
    "        # Append to current text block\n",
    "        current_text_block += element_text + \" \"\n",
    "        \n",
    "        if \"unstructured.documents.elements.ListItem\" in element_type_str:\n",
    "            list_items_raw.append(Element(type=\"list_item\", text=element_text)) # Keep original list item too if needed\n",
    "\n",
    "    elif \"unstructured.documents.elements.Table\" in element_type_str:\n",
    "        finalize_text_block() # Finalize current text block before a table\n",
    "        tables_raw.append(Element(type=\"table\", text=element_text))\n",
    "        current_context_prefix = \"\" # Tables often reset flow\n",
    "    elif \"unstructured.documents.elements.Image\" in element_type_str:\n",
    "        finalize_text_block() # Finalize current text block before an image\n",
    "        image_path = getattr(element.metadata, \"image_path\", \"N/A\")\n",
    "        images_raw.append(Element(type=\"image\", text=image_path))\n",
    "        current_context_prefix = \"\" # Images often reset flow\n",
    "    elif \"unstructured.documents.elements.FigureCaption\" in element_type_str:\n",
    "        finalize_text_block() # Finalize current text block before a caption\n",
    "        figure_captions_raw.append(Element(type=\"figure_caption\", text=element_text))\n",
    "        current_context_prefix = \"\" # Captions are usually self-contained\n",
    "    elif \"unstructured.documents.elements.Footer\" in element_type_str:\n",
    "        # Footers are generally ignored for main text, but can be logged if needed\n",
    "        footers_raw.append(Element(type=\"footer\", text=element_text))\n",
    "\n",
    "# Finalize any remaining text block after the loop\n",
    "finalize_text_block()\n",
    "\n",
    "# Now, 'texts' should contain the cleaned and combined narrative chunks\n",
    "texts = [e.text for e in text_for_semantic_chunking] # text_for_semantic_chunking already contains processed Elements\n",
    "tables = [e.text for e in tables_raw] # Tables are ready as is\n",
    "\n",
    "print(f\"Number of tables extracted: {len(tables)}\")\n",
    "print(f\"Number of text elements for semantic chunking: {len(texts)}\")\n",
    "print(f\"Number of images detected: {len(images_raw)}\")\n",
    "print(f\"Number of headers: {len(headers_raw)}\")\n",
    "print(f\"Number of titles: {len(titles_raw)}\")\n",
    "print(f\"Number of footers (ignored for RAG): {len(footers_raw)}\")\n",
    "print(f\"Number of figure captions: {len(figure_captions_raw)}\")\n",
    "print(f\"Number of list items: {len(list_items_raw)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inspecting raw_pdf_elements metadata for categorization ---\n",
      "Element Type: <class 'unstructured.documents.elements.Header'>\n",
      "Element Content (first 100 chars): 21_095300 ch18.qxp 10/29/07 3:49 PM Page 491...\n",
      "Element Metadata: {'detection_class_prob': 0.6735454201698303, 'coordinates': {'points': ((159.72222222222223, 40.42222222222228), (159.72222222222223, 63.15275573730469), (807.848388671875, 63.15275573730469), (807.848388671875, 40.42222222222228)), 'system': 'PixelSpace', 'layout_width': 1525, 'layout_height': 2150}, 'last_modified': '2025-06-09T13:49:51', 'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'file_directory': './data', 'filename': 'shortExample2_Nutrition_20Pgs.pdf'}\n",
      "Metadata Category: N/A\n",
      "Metadata Text As Entered: N/A\n",
      "------------------------------\n",
      "Element Type: <class 'unstructured.documents.elements.Title'>\n",
      "Element Content (first 100 chars): WY...\n",
      "Element Metadata: {'coordinates': {'points': ((746.0, 69.0), (746.0, 83.0), (779.0, 83.0), (779.0, 69.0)), 'system': 'PixelSpace', 'layout_width': 1525, 'layout_height': 2150}, 'last_modified': '2025-06-09T13:49:51', 'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'parent_id': '4f70a48067702e18fc3be215010c4dcf', 'file_directory': './data', 'filename': 'shortExample2_Nutrition_20Pgs.pdf'}\n",
      "Metadata Category: N/A\n",
      "Metadata Text As Entered: N/A\n",
      "------------------------------\n",
      "Element Type: <class 'unstructured.documents.elements.Title'>\n",
      "Element Content (first 100 chars): NUTRITION...\n",
      "Element Metadata: {'detection_class_prob': 0.6513950228691101, 'coordinates': {'points': ((534.2836111111111, 567.1324999999999), (534.2836111111111, 678.243611111111), (1010.5098266601562, 678.243611111111), (1010.5098266601562, 567.1324999999999)), 'system': 'PixelSpace', 'layout_width': 1525, 'layout_height': 2150}, 'last_modified': '2025-06-09T13:49:51', 'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'parent_id': '4f70a48067702e18fc3be215010c4dcf', 'file_directory': './data', 'filename': 'shortExample2_Nutrition_20Pgs.pdf'}\n",
      "Metadata Category: N/A\n",
      "Metadata Text As Entered: N/A\n",
      "------------------------------\n",
      "Element Type: <class 'unstructured.documents.elements.NarrativeText'>\n",
      "Element Content (first 100 chars): Compared to humans, the cat’s sense of taste is far less refined. We have 9,000 taste buds, while ca...\n",
      "Element Metadata: {'detection_class_prob': 0.9270253777503967, 'coordinates': {'points': ((309.2937927246094, 793.2813888888887), (309.2937927246094, 926.5730555555554), (1236.9376220703125, 926.5730555555554), (1236.9376220703125, 793.2813888888887)), 'system': 'PixelSpace', 'layout_width': 1525, 'layout_height': 2150}, 'last_modified': '2025-06-09T13:49:51', 'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'parent_id': '91b03bebb14ff3571b7c2c52610a4ead', 'file_directory': './data', 'filename': 'shortExample2_Nutrition_20Pgs.pdf'}\n",
      "Metadata Category: N/A\n",
      "Metadata Text As Entered: N/A\n",
      "------------------------------\n",
      "Element Type: <class 'unstructured.documents.elements.NarrativeText'>\n",
      "Element Content (first 100 chars): Cats are responsive to the basic tastes of sour, bitter, and salty. Recent stud- ies have shown that...\n",
      "Element Metadata: {'detection_class_prob': 0.9286258816719055, 'coordinates': {'points': ((306.35894775390625, 932.1147222222221), (306.35894775390625, 1030.6980555555554), (1238.634033203125, 1030.6980555555554), (1238.634033203125, 932.1147222222221)), 'system': 'PixelSpace', 'layout_width': 1525, 'layout_height': 2150}, 'last_modified': '2025-06-09T13:49:51', 'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'parent_id': '91b03bebb14ff3571b7c2c52610a4ead', 'file_directory': './data', 'filename': 'shortExample2_Nutrition_20Pgs.pdf'}\n",
      "Metadata Category: N/A\n",
      "Metadata Text As Entered: N/A\n",
      "------------------------------\n",
      "Element Type: <class 'unstructured.documents.elements.NarrativeText'>\n",
      "Element Content (first 100 chars): The rough, prickly feline tongue is covered with tiny hooklike barbs. Cats use their tongues to remo...\n",
      "Element Metadata: {'detection_class_prob': 0.9353950023651123, 'coordinates': {'points': ((304.8912048339844, 1036.239722222222), (304.8912048339844, 1169.5313888888888), (1239.4652099609375, 1169.5313888888888), (1239.4652099609375, 1036.239722222222)), 'system': 'PixelSpace', 'layout_width': 1525, 'layout_height': 2150}, 'last_modified': '2025-06-09T13:49:51', 'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'parent_id': '91b03bebb14ff3571b7c2c52610a4ead', 'file_directory': './data', 'filename': 'shortExample2_Nutrition_20Pgs.pdf'}\n",
      "Metadata Category: N/A\n",
      "Metadata Text As Entered: N/A\n",
      "------------------------------\n",
      "Element Type: <class 'unstructured.documents.elements.NarrativeText'>\n",
      "Element Content (first 100 chars): Cats make up for their poor sense of taste with a superior sense of smell. In fact, both senses are ...\n",
      "Element Metadata: {'detection_class_prob': 0.9381471276283264, 'coordinates': {'points': ((311.3623046875, 1175.0730555555556), (311.3623046875, 1343.2298583984375), (1237.6202392578125, 1343.2298583984375), (1237.6202392578125, 1175.0730555555556)), 'system': 'PixelSpace', 'layout_width': 1525, 'layout_height': 2150}, 'last_modified': '2025-06-09T13:49:51', 'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'parent_id': '91b03bebb14ff3571b7c2c52610a4ead', 'file_directory': './data', 'filename': 'shortExample2_Nutrition_20Pgs.pdf'}\n",
      "Metadata Category: N/A\n",
      "Metadata Text As Entered: N/A\n",
      "------------------------------\n",
      "Element Type: <class 'unstructured.documents.elements.Title'>\n",
      "Element Content (first 100 chars): Basic Nutritional Requirements...\n",
      "Element Metadata: {'detection_class_prob': 0.8850095272064209, 'coordinates': {'points': ((315.0, 1405.5019444444442), (315.0, 1452.7241666666664), (959.8241666666669, 1452.7241666666664), (959.8241666666669, 1405.5019444444442)), 'system': 'PixelSpace', 'layout_width': 1525, 'layout_height': 2150}, 'last_modified': '2025-06-09T13:49:51', 'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'parent_id': '4f70a48067702e18fc3be215010c4dcf', 'file_directory': './data', 'filename': 'shortExample2_Nutrition_20Pgs.pdf'}\n",
      "Metadata Category: N/A\n",
      "Metadata Text As Entered: N/A\n",
      "------------------------------\n",
      "Element Type: <class 'unstructured.documents.elements.NarrativeText'>\n",
      "Element Content (first 100 chars): Cats are obligate carnivores, which means that in the wild, they subsist on a diet that consists onl...\n",
      "Element Metadata: {'detection_class_prob': 0.9396106600761414, 'coordinates': {'points': ((315.0, 1484.9480555555556), (315.0, 1653.003333333333), (1236.327392578125, 1653.003333333333), (1236.327392578125, 1484.9480555555556)), 'system': 'PixelSpace', 'layout_width': 1525, 'layout_height': 2150}, 'last_modified': '2025-06-09T13:49:51', 'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'parent_id': '3edffb30c7ca7ee4da9007c9a97ba0b8', 'file_directory': './data', 'filename': 'shortExample2_Nutrition_20Pgs.pdf'}\n",
      "Metadata Category: N/A\n",
      "Metadata Text As Entered: N/A\n",
      "------------------------------\n",
      "Element Type: <class 'unstructured.documents.elements.NarrativeText'>\n",
      "Element Content (first 100 chars): Due to their natural diet and certain enzyme deficiencies, cats are some- what uniquely adapted to m...\n",
      "Element Metadata: {'detection_class_prob': 0.9413050413131714, 'coordinates': {'points': ((314.4190368652344, 1658.5449999999998), (314.4190368652344, 1861.546630859375), (1236.1043701171875, 1861.546630859375), (1236.1043701171875, 1658.5449999999998)), 'system': 'PixelSpace', 'layout_width': 1525, 'layout_height': 2150}, 'last_modified': '2025-06-09T13:49:51', 'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'parent_id': '3edffb30c7ca7ee4da9007c9a97ba0b8', 'file_directory': './data', 'filename': 'shortExample2_Nutrition_20Pgs.pdf'}\n",
      "Metadata Category: N/A\n",
      "Metadata Text As Entered: N/A\n",
      "------------------------------\n",
      "Element Type: <class 'unstructured.documents.elements.Footer'>\n",
      "Element Content (first 100 chars): 491...\n",
      "Element Metadata: {'detection_class_prob': 0.6808841824531555, 'coordinates': {'points': ((747.6705555555556, 1894.1769444444442), (747.6705555555556, 1921.954722222222), (793.9983333333333, 1921.954722222222), (793.9983333333333, 1894.1769444444442)), 'system': 'PixelSpace', 'layout_width': 1525, 'layout_height': 2150}, 'last_modified': '2025-06-09T13:49:51', 'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'file_directory': './data', 'filename': 'shortExample2_Nutrition_20Pgs.pdf'}\n",
      "Metadata Category: N/A\n",
      "Metadata Text As Entered: N/A\n",
      "------------------------------\n",
      "Element Type: <class 'unstructured.documents.elements.Text'>\n",
      "Element Content (first 100 chars): —o—...\n",
      "Element Metadata: {'coordinates': {'points': ((696.0, 2050.0), (696.0, 2117.0), (829.0, 2117.0), (829.0, 2050.0)), 'system': 'PixelSpace', 'layout_width': 1525, 'layout_height': 2150}, 'last_modified': '2025-06-09T13:49:51', 'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'file_directory': './data', 'filename': 'shortExample2_Nutrition_20Pgs.pdf'}\n",
      "Metadata Category: N/A\n",
      "Metadata Text As Entered: N/A\n",
      "------------------------------\n",
      "Element Type: <class 'unstructured.documents.elements.Image'>\n",
      "Element Content (first 100 chars): ...\n",
      "Element Metadata: {'detection_class_prob': 0.27503135800361633, 'coordinates': {'points': ((687.0037231445312, 2064.61279296875), (687.0037231445312, 2104.54833984375), (836.4313354492188, 2104.54833984375), (836.4313354492188, 2064.61279296875)), 'system': 'PixelSpace', 'layout_width': 1525, 'layout_height': 2150}, 'last_modified': '2025-06-09T13:49:51', 'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'image_path': '/Users/mas/Desktop/LLM_Veterinary_AI/figures/figure-1-1.jpg', 'file_directory': './data', 'filename': 'shortExample2_Nutrition_20Pgs.pdf'}\n",
      "Metadata Category: N/A\n",
      "Metadata Text As Entered: N/A\n",
      "------------------------------\n",
      "Element Type: <class 'unstructured.documents.elements.Text'>\n",
      "Element Content (first 100 chars): 18...\n",
      "Element Metadata: {'coordinates': {'points': ((1201.1494444444445, 278.8747222222222), (1201.1494444444445, 412.2080555555556), (1328.7227777777778, 412.2080555555556), (1328.7227777777778, 278.8747222222222)), 'system': 'PixelSpace', 'layout_width': 1525, 'layout_height': 2150}, 'last_modified': '2025-06-09T13:49:51', 'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'file_directory': './data', 'filename': 'shortExample2_Nutrition_20Pgs.pdf'}\n",
      "Metadata Category: N/A\n",
      "Metadata Text As Entered: N/A\n",
      "------------------------------\n",
      "Element Type: <class 'unstructured.documents.elements.Header'>\n",
      "Element Content (first 100 chars): 21_095300 ch18.qxp 10/29/07 3:49 PM Page 492...\n",
      "Element Metadata: {'detection_class_prob': 0.7663038372993469, 'coordinates': {'points': ((159.72222222222223, 40.42222222222228), (159.72222222222223, 63.28798294067383), (807.4633178710938, 63.28798294067383), (807.4633178710938, 40.42222222222228)), 'system': 'PixelSpace', 'layout_width': 1525, 'layout_height': 2150}, 'last_modified': '2025-06-09T13:49:51', 'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 2, 'file_directory': './data', 'filename': 'shortExample2_Nutrition_20Pgs.pdf'}\n",
      "Metadata Category: N/A\n",
      "Metadata Text As Entered: N/A\n",
      "------------------------------\n",
      "Element Type: <class 'unstructured.documents.elements.Text'>\n",
      "Element Content (first 100 chars): ‘7 7...\n",
      "Element Metadata: {'coordinates': {'points': ((746.0, 29.0), (746.0, 104.0), (788.0, 104.0), (788.0, 29.0)), 'system': 'PixelSpace', 'layout_width': 1525, 'layout_height': 2150}, 'last_modified': '2025-06-09T13:49:51', 'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 2, 'parent_id': 'f603115f6d490a44343e5b419924efa4', 'file_directory': './data', 'filename': 'shortExample2_Nutrition_20Pgs.pdf'}\n",
      "Metadata Category: N/A\n",
      "Metadata Text As Entered: N/A\n",
      "------------------------------\n",
      "Element Type: <class 'unstructured.documents.elements.NarrativeText'>\n",
      "Element Content (first 100 chars): 492 • CAT OWNER’S HOME VETERINARY HANDBOOK...\n",
      "Element Metadata: {'detection_class_prob': 0.5524212121963501, 'coordinates': {'points': ((249.30111694335938, 248.77583333333334), (249.30111694335938, 278.3869444444447), (828.8001098632812, 278.3869444444447), (828.8001098632812, 248.77583333333334)), 'system': 'PixelSpace', 'layout_width': 1525, 'layout_height': 2150}, 'last_modified': '2025-06-09T13:49:51', 'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 2, 'parent_id': 'f603115f6d490a44343e5b419924efa4', 'file_directory': './data', 'filename': 'shortExample2_Nutrition_20Pgs.pdf'}\n",
      "Metadata Category: N/A\n",
      "Metadata Text As Entered: N/A\n",
      "------------------------------\n",
      "Element Type: <class 'unstructured.documents.elements.NarrativeText'>\n",
      "Element Content (first 100 chars): used for energy but also for a healthy nervous system, skin, and many meta- bolic processes. Ideally...\n",
      "Element Metadata: {'detection_class_prob': 0.902752697467804, 'coordinates': {'points': ((293.5769958496094, 348.5963888888888), (293.5769958496094, 412.4713888888888), (1212.0150146484375, 412.4713888888888), (1212.0150146484375, 348.5963888888888)), 'system': 'PixelSpace', 'layout_width': 1525, 'layout_height': 2150}, 'last_modified': '2025-06-09T13:49:51', 'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 2, 'parent_id': 'f603115f6d490a44343e5b419924efa4', 'file_directory': './data', 'filename': 'shortExample2_Nutrition_20Pgs.pdf'}\n",
      "Metadata Category: N/A\n",
      "Metadata Text As Entered: N/A\n",
      "------------------------------\n",
      "Element Type: <class 'unstructured.documents.elements.NarrativeText'>\n",
      "Element Content (first 100 chars): Cats lack many of the amylases, which are enzymes that aid in carbohy- drate digestion. Large amount...\n",
      "Element Metadata: {'detection_class_prob': 0.9213013052940369, 'coordinates': {'points': ((282.4761962890625, 418.01305555555547), (282.4761962890625, 516.5963888888888), (1217.4925537109375, 516.5963888888888), (1217.4925537109375, 418.01305555555547)), 'system': 'PixelSpace', 'layout_width': 1525, 'layout_height': 2150}, 'last_modified': '2025-06-09T13:49:51', 'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 2, 'parent_id': 'f603115f6d490a44343e5b419924efa4', 'file_directory': './data', 'filename': 'shortExample2_Nutrition_20Pgs.pdf'}\n",
      "Metadata Category: N/A\n",
      "Metadata Text As Entered: N/A\n",
      "------------------------------\n",
      "Element Type: <class 'unstructured.documents.elements.NarrativeText'>\n",
      "Element Content (first 100 chars): The basic nutritional requirements for cats are listed in the table below. In this table, minimal re...\n",
      "Element Metadata: {'detection_class_prob': 0.9483627676963806, 'coordinates': {'points': ((300.0, 522.1380555555555), (300.0, 794.2630555555556), (1208.3783333333329, 794.2630555555556), (1208.3783333333329, 522.1380555555555)), 'system': 'PixelSpace', 'layout_width': 1525, 'layout_height': 2150}, 'last_modified': '2025-06-09T13:49:51', 'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 2, 'parent_id': 'f603115f6d490a44343e5b419924efa4', 'file_directory': './data', 'filename': 'shortExample2_Nutrition_20Pgs.pdf'}\n",
      "Metadata Category: N/A\n",
      "Metadata Text As Entered: N/A\n",
      "------------------------------\n",
      "\n",
      "Overall element type counts from raw_pdf_elements (after partition_pdf):\n",
      "{\"<class 'unstructured.documents.elements.Header'>\": 22, \"<class 'unstructured.documents.elements.Title'>\": 61, \"<class 'unstructured.documents.elements.NarrativeText'>\": 158, \"<class 'unstructured.documents.elements.Footer'>\": 1, \"<class 'unstructured.documents.elements.Text'>\": 27, \"<class 'unstructured.documents.elements.Image'>\": 21, \"<class 'unstructured.documents.elements.FigureCaption'>\": 3, \"<class 'unstructured.documents.elements.Table'>\": 4, \"<class 'unstructured.documents.elements.ListItem'>\": 19}\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Inspecting raw_pdf_elements metadata for categorization ---\")\n",
    "for i, element in enumerate(raw_pdf_elements):\n",
    "    if i >= 20:  # Limit to first 20 elements for brevity\n",
    "        break\n",
    "    print(f\"Element Type: {type(element)}\")\n",
    "    print(f\"Element Content (first 100 chars): {str(element)[:100]}...\")\n",
    "    if hasattr(element, 'metadata') and element.metadata:\n",
    "        print(f\"Element Metadata: {element.metadata.to_dict()}\") # Convert to dict for easier viewing\n",
    "        print(f\"Metadata Category: {getattr(element.metadata, 'category', 'N/A')}\")\n",
    "        print(f\"Metadata Text As Entered: {getattr(element.metadata, 'text_as_entered', 'N/A')}\")\n",
    "    else:\n",
    "        print(\"No metadata available for this element.\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# Also print the overall counts for all element types returned by partition_pdf\n",
    "category_counts = {}\n",
    "for element in raw_pdf_elements:\n",
    "    category = str(type(element))\n",
    "    category_counts[category] = category_counts.get(category, 0) + 1\n",
    "print(\"\\nOverall element type counts from raw_pdf_elements (after partition_pdf):\")\n",
    "print(category_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text & Table Summary Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "# Prompt\n",
    "model = ChatOllama(model=\"llama3.2\")\n",
    "\n",
    "# New: Text Summarization Prompt\n",
    "prompt_text_summary = \"\"\"You are an assistant tasked with concisely summarizing text sections related to veterinary advice and pet care. Focus on key information, main ideas, and any actionable advice. Text chunk: {element} \"\"\"\n",
    "prompt_text = ChatPromptTemplate.from_template(prompt_text_summary)\n",
    "text_summarize_chain = {\"element\": lambda x: x} | prompt_text | model | StrOutputParser()\n",
    "\n",
    "# New: Table Summarization Prompt\n",
    "prompt_table_summary = \"\"\"You are an assistant tasked with extracting key data, trends, and important numerical information from the provided table, especially when related to pet nutrition, health, or statistics. Give a concise summary. Table chunk: {element} \"\"\"\n",
    "prompt_table = ChatPromptTemplate.from_template(prompt_table_summary)\n",
    "table_summarize_chain = {\"element\": lambda x: x} | prompt_table | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply to text\n",
    "# texts = [i.text for i in text_elements if i.text != \"\"]\n",
    "text_summaries = text_summarize_chain.batch(texts, {\"max_concurrency\": 8})\n",
    "\n",
    "# Apply to tables\n",
    "# tables = [i.text for i in table_elements]\n",
    "table_summaries = table_summarize_chain.batch(tables, {\"max_concurrency\": 8})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Summary Generatetion\n",
    "From the LangChain Cookbook, they used a LLaVA 7B model to generate image summaries in .txt. Those files will be in the same dir as those images. However, I have llama3.2-vision already installed and setup on my local machine. \n",
    "\n",
    "Llama3.2-vision model is a 11B model which may require a strong computing power and large memory. Switch model if necessary. i.e. Llava, Qwen, Gemma, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ⚠️Patch:\n",
    "Generic query often won't trigger the LLM to include image in the response. AI analysis shows it could be a problem of how images summaries were created. Retriever performs sematic matching to retrieve relevant chunks, but the current summaries was written in a outsider perspective. It'd be better to try following prompt in making summaries.\n",
    "\n",
    "'content': 'Describe the image in detail, focusing on any actions, techniques, or procedures depicted related to pet handling or care. Explain the purpose or context of the actions shown, if clear. Be concise and relevant to veterinary advice.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✅ Side Note:\n",
    "There are many irrelevant images exist in the textbook, like paragraph divider, section dividers, etc. In future development, consider using a **Node/Agent** to decide if a image should be filtered out for summarization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Working on summary for figure-8-6.jpg\n",
      "✅ Summary for figure-8-6.jpg saved to ./figures/shortExample2/figure-8-6.txt\n",
      "⏳ Working on summary for figure-20-20.jpg\n",
      "✅ Summary for figure-20-20.jpg saved to ./figures/shortExample2/figure-20-20.txt\n",
      "⏳ Working on summary for figure-13-11.jpg\n",
      "✅ Summary for figure-13-11.jpg saved to ./figures/shortExample2/figure-13-11.txt\n",
      "⏳ Working on summary for figure-15-14.jpg\n",
      "✅ Summary for figure-15-14.jpg saved to ./figures/shortExample2/figure-15-14.txt\n",
      "⏳ Working on summary for figure-9-7.jpg\n",
      "✅ Summary for figure-9-7.jpg saved to ./figures/shortExample2/figure-9-7.txt\n",
      "⏳ Working on summary for figure-17-16.jpg\n",
      "✅ Summary for figure-17-16.jpg saved to ./figures/shortExample2/figure-17-16.txt\n",
      "⏳ Working on summary for figure-5-3.jpg\n",
      "✅ Summary for figure-5-3.jpg saved to ./figures/shortExample2/figure-5-3.txt\n",
      "⏳ Working on summary for figure-19-18.jpg\n",
      "✅ Summary for figure-19-18.jpg saved to ./figures/shortExample2/figure-19-18.txt\n",
      "⏳ Working on summary for figure-7-5.jpg\n",
      "✅ Summary for figure-7-5.jpg saved to ./figures/shortExample2/figure-7-5.txt\n",
      "⏳ Working on summary for figure-12-10.jpg\n",
      "✅ Summary for figure-12-10.jpg saved to ./figures/shortExample2/figure-12-10.txt\n",
      "⏳ Working on summary for figure-11-9.jpg\n",
      "✅ Summary for figure-11-9.jpg saved to ./figures/shortExample2/figure-11-9.txt\n",
      "⏳ Working on summary for figure-19-19.jpg\n",
      "✅ Summary for figure-19-19.jpg saved to ./figures/shortExample2/figure-19-19.txt\n",
      "⏳ Working on summary for figure-21-21.jpg\n",
      "✅ Summary for figure-21-21.jpg saved to ./figures/shortExample2/figure-21-21.txt\n",
      "⏳ Working on summary for figure-1-1.jpg\n",
      "✅ Summary for figure-1-1.jpg saved to ./figures/shortExample2/figure-1-1.txt\n",
      "⏳ Working on summary for figure-4-2.jpg\n",
      "✅ Summary for figure-4-2.jpg saved to ./figures/shortExample2/figure-4-2.txt\n",
      "⏳ Working on summary for figure-18-17.jpg\n",
      "✅ Summary for figure-18-17.jpg saved to ./figures/shortExample2/figure-18-17.txt\n",
      "⏳ Working on summary for figure-14-13.jpg\n",
      "✅ Summary for figure-14-13.jpg saved to ./figures/shortExample2/figure-14-13.txt\n",
      "⏳ Working on summary for figure-14-12.jpg\n",
      "✅ Summary for figure-14-12.jpg saved to ./figures/shortExample2/figure-14-12.txt\n",
      "⏳ Working on summary for figure-10-8.jpg\n",
      "✅ Summary for figure-10-8.jpg saved to ./figures/shortExample2/figure-10-8.txt\n",
      "⏳ Working on summary for figure-16-15.jpg\n",
      "✅ Summary for figure-16-15.jpg saved to ./figures/shortExample2/figure-16-15.txt\n",
      "⏳ Working on summary for figure-6-4.jpg\n",
      "✅ Summary for figure-6-4.jpg saved to ./figures/shortExample2/figure-6-4.txt\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import os\n",
    "import base64\n",
    "\n",
    "# Directories\n",
    "image_directory = \"./figures/shortExample2/\"\n",
    "output_directory = \"./figures/shortExample2/\"\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Supported image formats\n",
    "supported_extensions = ('.png', '.jpg', '.jpeg')\n",
    "\n",
    "for filename in os.listdir(image_directory):\n",
    "    if filename.lower().endswith(supported_extensions):\n",
    "        image_path = os.path.join(image_directory, filename)\n",
    "        output_filename = os.path.splitext(filename)[0] + \".txt\"\n",
    "        output_path = os.path.join(output_directory, output_filename)\n",
    "\n",
    "        print(f\"⏳ Working on summary for {filename}\")\n",
    "\n",
    "        # Check if the summary file already exists\n",
    "        if os.path.exists(output_path):\n",
    "            print(f\"☑️ Summary for {filename} already exists at {output_path}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Read and encode image in base64\n",
    "            with open(image_path, 'rb') as f:\n",
    "                image_data = base64.b64encode(f.read()).decode('utf-8')\n",
    "\n",
    "            # Send image to ollama for vision model processing\n",
    "            response = ollama.chat(\n",
    "                model='llava:7b',\n",
    "                messages=[\n",
    "                    {\n",
    "                        'role': 'user',\n",
    "                        'content': 'Describe the image in detail, focusing on any actions, techniques, or procedures depicted related to pet handling or care. Explain the purpose or context of the actions shown, if clear. Be concise and relevant to veterinary advice. If you think the images has nothing to do with veterinary, do not do anything.',  \n",
    "                        'images': [image_data]\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            # Extract and save the generated summary\n",
    "            summary = response['message']['content']\n",
    "            \n",
    "            with open(output_path, 'w') as f:\n",
    "                f.write(summary)\n",
    "\n",
    "            print(f\"✅ Summary for {filename} saved to {output_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {filename}: {e}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read image and summaries from folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./figures/shortExample2/figure-15-14.jpg',\n",
       " './figures/shortExample2/figure-20-20.jpg',\n",
       " './figures/shortExample2/figure-14-12.jpg',\n",
       " './figures/shortExample2/figure-19-18.jpg']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "path =  \"./figures/shortExample2/\"\n",
    "# Get all .txt files in the directory\n",
    "file_paths = glob.glob(os.path.expanduser(os.path.join(path, \"*.txt\")))\n",
    "\n",
    "# Supported image formats\n",
    "supported_extensions = ('.png', '.jpg', '.jpeg')\n",
    "\n",
    "# Read each file and store its content in a list, and collect corresponding image paths\n",
    "img_summaries = []\n",
    "image_paths = []\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, \"r\") as file:\n",
    "        img_summaries.append(file.read())\n",
    "    \n",
    "    # Derive the original image path from the summary file path\n",
    "    base_filename = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    found_image_path = None\n",
    "    for ext in supported_extensions:\n",
    "        potential_image_path = os.path.join(path, base_filename + ext)\n",
    "        if os.path.exists(potential_image_path):\n",
    "            found_image_path = potential_image_path\n",
    "            break\n",
    "    image_paths.append(found_image_path)\n",
    "\n",
    "# Clean up residual logging\n",
    "# cleaned_img_summary = [\n",
    "#     s.split(\"clip_model_load: total allocated memory: 201.27 MB\\\\n\\\\n\", 1)[1].strip() #Llava Model could left this message at every summary. This line is here to remove the overhead.\n",
    "#     for s in img_summaries\n",
    "# ]\n",
    "\n",
    "# Filter out entries where no corresponding image was found\n",
    "# This ensures cleaned_img_summary and image_paths remain aligned\n",
    "# filtered_img_summaries = []\n",
    "# filtered_image_paths = []\n",
    "# for i, summary in enumerate(cleaned_img_summary):\n",
    "#     if image_paths[i] is not None:\n",
    "#         filtered_img_summaries.append(summary)\n",
    "#         filtered_image_paths.append(image_paths[i])\n",
    "\n",
    "cleaned_img_summary = img_summaries\n",
    "image_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, storing all those in a vector DB.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# The vectorstore to use to index the child chunks\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"summaries\", embedding_function=GPT4AllEmbeddings()\n",
    ")\n",
    "\n",
    "# The storage layer for the parent documents\n",
    "store = InMemoryStore()  # <- Can we extend this to images\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "# The retriever (empty to start)\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    id_key=id_key,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chroma collection 'summaries' has been deleted.\n"
     ]
    }
   ],
   "source": [
    "# Ensure you have initialized your vectorstore variable (e.g., by running previous cells)\n",
    "# This will delete the Chroma collection named \"summaries\"\n",
    "vectorstore.delete_collection()\n",
    "print(\"Chroma collection 'summaries' has been deleted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add texts\n",
    "if texts:\n",
    "    doc_ids = [str(uuid.uuid4()) for _ in texts]\n",
    "    summary_texts = [\n",
    "        Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
    "        for i, s in enumerate(text_summaries)\n",
    "    ]\n",
    "    retriever.vectorstore.add_documents(summary_texts)\n",
    "    retriever.docstore.mset(list(zip(doc_ids, texts)))\n",
    "\n",
    "\n",
    "# Add tables\n",
    "if tables:\n",
    "    table_ids = [str(uuid.uuid4()) for _ in tables]\n",
    "    summary_tables = [\n",
    "        Document(page_content=s, metadata={id_key: table_ids[i]})\n",
    "        for i, s in enumerate(table_summaries)\n",
    "    ]\n",
    "    retriever.vectorstore.add_documents(summary_tables)\n",
    "    retriever.docstore.mset(list(zip(table_ids, tables)))\n",
    "\n",
    "    # Add images\n",
    "# Add images\n",
    "if cleaned_img_summary:\n",
    "    img_ids = [str(uuid.uuid4()) for _ in cleaned_img_summary]\n",
    "    summary_img = [\n",
    "        Document(page_content=s, metadata={id_key: img_ids[i]})\n",
    "        for i, s in enumerate(cleaned_img_summary)\n",
    "    ]\n",
    "    retriever.vectorstore.add_documents(summary_img)\n",
    "    # Store the image path as the raw document for retrieval\n",
    "    retriever.docstore.mset(\n",
    "        list(zip(img_ids, image_paths))\n",
    "    )\n",
    " # Store the image summary as the raw document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./figures/shortExample2/figure-14-12.jpg',\n",
       " './figures/shortExample2/figure-15-14.jpg',\n",
       " './figures/shortExample2/figure-20-20.jpg',\n",
       " './figures/shortExample2/figure-19-18.jpg']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try_result = retriever.invoke(\"Images / figures with cat in a white background\")\n",
    "try_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import re\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_core.messages import HumanMessage\n",
    "from PIL import Image\n",
    "\n",
    "def plt_img_base64(img_base64):\n",
    "    \"\"\"Disply base64 encoded string as image\"\"\"\n",
    "    # Create an HTML img tag with the base64 string as the source\n",
    "    image_html = f'<img src=\"data:image/jpeg;base64,{img_base64}\" />'\n",
    "    # Display the image by rendering the HTML\n",
    "    display(HTML(image_html))\n",
    "\n",
    "def looks_like_base64(sb):\n",
    "    \"\"\"Check if the string looks like base64\"\"\"\n",
    "    return re.match(\"^[A-Za-z0-9+/]+[=]{0,2}$\", sb) is not None\n",
    "\n",
    "\n",
    "\n",
    "def split_image_text_types(docs):\n",
    "    \"\"\"\n",
    "    Split base64-encoded images and texts from a list of documents/strings.\n",
    "    Handles both Document objects and direct image path strings.\n",
    "    Only the first identified image will be base64 encoded and marked for Markdown rendering.\n",
    "    Subsequent image paths will be added as plain text references.\n",
    "    \"\"\"\n",
    "    b64_images = []\n",
    "    texts = []\n",
    "    image_processed = False # Flag to ensure only one image is processed visually\n",
    "\n",
    "    for doc in docs:\n",
    "        # Determine the content based on whether 'doc' is a Document object or a string\n",
    "        doc_content = doc.page_content if isinstance(doc, Document) else str(doc)\n",
    "\n",
    "        # Check if the content is an image path and if the file exists\n",
    "        if doc_content.lower().endswith(('.png', '.jpg', '.jpeg')) and os.path.exists(doc_content):\n",
    "            if not image_processed: # Process only the first image visually\n",
    "                image_path = doc_content\n",
    "                try:\n",
    "                    with open(image_path, 'rb') as f:\n",
    "                        image_data = base64.b64encode(f.read()).decode('utf-8')\n",
    "                        resized_image_data = resize_base64_image(image_data, size=(1300, 600))\n",
    "                        b64_images.append(resized_image_data)\n",
    "                    # Add the image path for Markdown rendering in the LLM response\n",
    "                    texts.append(f\"IMAGE_PATH_FOR_MD: {image_path}\")\n",
    "                    image_processed = True # Set flag to true after processing the first image\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading image {image_path}: {e}\")\n",
    "                    texts.append(doc_content) # If error, treat as text\n",
    "            else:\n",
    "                # For subsequent image paths, just add a textual reference without the special tag\n",
    "                texts.append(f\"An additional image related to the context was found at: {os.path.basename(doc_content)}\")\n",
    "        else:\n",
    "            # It's text or a table summary\n",
    "            texts.append(doc_content)\n",
    "    return {\"images\": b64_images, \"texts\": texts}\n",
    "\n",
    "\n",
    "def img_prompt_func(data_dict):\n",
    "    \"\"\"\n",
    "    Construct the messages for the multimodal LLM.\n",
    "    `data_dict` will contain keys: 'context' (which is {'images': [...], 'texts': [...]}) and 'question'.\n",
    "    Instructs the LLM to render ALL image paths found via Markdown, striving to include images where relevant.\n",
    "    \"\"\"\n",
    "    formatted_texts = \"\\n\".join(data_dict[\"context\"][\"texts\"])\n",
    "    messages = []\n",
    "\n",
    "    # Debugging: Print images being passed to the model\n",
    "    print(f\"DEBUG: Images being passed to LLM (visually): {len(data_dict['context']['images'])} image(s)\")\n",
    "    if data_dict[\"context\"][\"images\"]:\n",
    "        print(f\"DEBUG: First visual image (base64 snippet): {data_dict['context']['images'][0][:50]}...\")\n",
    "\n",
    "    # Adding image(s) to the messages if present (this is the visual input)\n",
    "    if data_dict[\"context\"][\"images\"]:\n",
    "        for image in data_dict[\"context\"][\"images\"]:\n",
    "            image_message = {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image}\"},\n",
    "            }\n",
    "            messages.append(image_message)\n",
    "\n",
    "    # Adding the text for analysis, with stronger instructions for Markdown rendering\n",
    "    text_message = {\n",
    "        \"type\": \"text\",\n",
    "        \"text\": (\n",
    "            \"You are a veterinary assistant tasked with providing veterinary advice. \"\n",
    "            \"You will be given a mixed of text, tables, and image references. \"\n",
    "            \"Your primary goal is to use all provided information, including images, to answer the user's question comprehensively. \"\n",
    "            \"It is ESSENTIAL that you identify ALL instances of `IMAGE_PATH_FOR_MD: /path/to/image.jpg` in the context \"\n",
    "            \"and convert them directly into Markdown image syntax within your response. \"\n",
    "            \"For each image, provide a brief, accurate alt text description like `![Description of image content](/path/to/image.jpg)`. \"\n",
    "            \"For example, if the context contains `IMAGE_PATH_FOR_MD: ./figures/cat_pickup.jpg`, you MUST output `![Illustration of cat pickup technique](./figures/cat_pickup.jpg)`. \"\n",
    "            \"Include these Markdown images strategically where they best illustrate your points in the answer. \"\n",
    "            \"Do NOT omit any `IMAGE_PATH_FOR_MD:` entries; they must be rendered as Markdown images. \"\n",
    "            f\"User-provided question: {data_dict['question']}\\n\\n\"\n",
    "            \"Text and / or tables:\\n\"\n",
    "            f\"{formatted_texts}\"\n",
    "        ),\n",
    "    }\n",
    "    messages.append(text_message)\n",
    "    return [HumanMessage(content=messages)]\n",
    "\n",
    "def is_image_data(b64data):\n",
    "    \"\"\"\n",
    "    Check if the base64 data is an image by looking at the start of the data\n",
    "    \"\"\"\n",
    "    image_signatures = {\n",
    "        b\"\\xff\\xd8\\xff\": \"jpg\",\n",
    "        b\"\\x89\\x50\\x4e\\x47\\x0d\\x0a\\x1a\\x0a\": \"png\",\n",
    "        b\"\\x47\\x49\\x46\\x38\": \"gif\",\n",
    "        b\"\\x52\\x49\\x46\\x46\": \"webp\",\n",
    "    }\n",
    "    try:\n",
    "        header = base64.b64decode(b64data)[:8]  # Decode and get the first 8 bytes\n",
    "        for sig, format in image_signatures.items():\n",
    "            if header.startswith(sig):\n",
    "                return True\n",
    "        return False\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "def resize_base64_image(base64_string, size=(128, 128)):\n",
    "    \"\"\"\n",
    "    Resize an image encoded as a Base64 string\n",
    "    \"\"\"\n",
    "    # Decode the Base64 string\n",
    "    img_data = base64.b64decode(base64_string)\n",
    "    img = Image.open(io.BytesIO(img_data))\n",
    "\n",
    "    # Resize the image\n",
    "    resized_img = img.resize(size, Image.LANCZOS)\n",
    "\n",
    "    # Save the resized image to a bytes buffer\n",
    "    buffered = io.BytesIO()\n",
    "    resized_img.save(buffered, format=img.format)\n",
    "\n",
    "    # Encode the resized image to Base64\n",
    "    return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def multi_modal_rag_chain(retriever):\n",
    "    \"\"\"\n",
    "    Multi-modal RAG chain\n",
    "    \"\"\"\n",
    "\n",
    "    # Multi-modal LLM\n",
    "    model = ChatOllama(model=\"llama3.2-vision\")\n",
    "\n",
    "    # RAG pipeline\n",
    "    chain = (\n",
    "        {\n",
    "            \"context\": retriever | RunnableLambda(split_image_text_types),\n",
    "            \"question\": RunnablePassthrough(),\n",
    "        }\n",
    "        | RunnableLambda(img_prompt_func) # This consumes the {\"context\": {\"images\": ..., \"texts\": ...}, \"question\": ...} dict\n",
    "        | model\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    return chain\n",
    "\n",
    "# Create RAG chain\n",
    "# Assuming 'retriever' is already defined from previous cells\n",
    "chain_multimodal_rag = multi_modal_rag_chain(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check retrieval\n",
    "query = \"What kind of cat need more calories per day?\"\n",
    "docs = retriever.invoke(query, limit=8)\n",
    "\n",
    "# We get 4 docs\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 4 documents:\n",
      "\n",
      "--- Document 1 ---\n",
      "Text Content:\n",
      "Counting Calories\n",
      "\n",
      "Unless maintaining a good body weight is a problem, senior cats should be on a reduced-calorie diet. In general, an older cat who is neither too fat nor too thin needs about 20 calories per pound (.45 kg) of body weight per day—and sometimes even less—to meet her caloric needs. These are guidelines, and the exact amount needed to keep your cat at an ideal weight may vary. Various health conditions may also dictate that your cat needs more or fewer calories.\n",
      "\n",
      "--- Document 2 ---\n",
      "Text Content:\n",
      "1 The values for amount per kilogram of dry matter have been calculated assuming a dietary energy density of 4,000 calories ME per kilogram of food. If the energy density of the diet is not 4,000 calo- ries ME per kilogram, then to calculate the per kilogram of dry matter for each nutrient, multiply the value for the nutrient by the energy density of the pet food (in calories ME per kilogram) and divide by 4,000.\n",
      "\n",
      "2 0.02 g arginine should be added for every gram of crude protein above 200 g for the Recommended\n",
      "\n",
      "--- Document 3 ---\n",
      "Text Content:\n",
      "FEEDING ADULT CATS\n",
      "\n",
      "The actual amount of food a cat needs varies among cats of equal weight because of differences in metabolic rate and activity level. Labels only provide guidelines—the actual amount to feed must be customized to the individual cat. Spayed and neutered cats have a much lower metabolism than intact cats.\n",
      "\n",
      "Generally, an active adult cat will need about 30 to 35 calories per pound (.45 kg) of body weight per day, and some will do well with about 25 calories per pound per day. An inactive cat will need about 18 calories per pound (.45 kg) of body weight per day. Even if they are active, many spayed and neutered cats do very well on the lower calorie estimate.\n",
      "\n",
      "Pregnant and nursing cats have much higher requirements—figure about 45 calories per pound of body weight per day during the last trimester of preg- nancy and as high as 140 calories per pound during the peak of lactation.\n",
      "\n",
      "—o—\n",
      "\n",
      "21_095300 ch18.qxp 10/29/07 3:49 PM Page 504\n",
      "\n",
      "--- Document 4 ---\n",
      "Text Content:\n",
      "491\n",
      "\n",
      "—o—\n",
      "\n",
      "18\n",
      "\n",
      "21_095300 ch18.qxp 10/29/07 3:49 PM Page 492\n",
      "\n",
      "‘7 7\n",
      "\n",
      "492 • CAT OWNER’S HOME VETERINARY HANDBOOK\n",
      "\n",
      "used for energy but also for a healthy nervous system, skin, and many meta- bolic processes. Ideally, a cat’s diet should be at least 9 percent fat.\n",
      "\n",
      "Cats lack many of the amylases, which are enzymes that aid in carbohy- drate digestion. Large amounts of carbohydrates may decrease the efficiency of protein digestion as well as cause high levels of blood glucose.\n",
      "\n",
      "--- LLM Response ---\n",
      "DEBUG: Images being passed to LLM (visually): 0 image(s)\n",
      "The type of cat that needs more calories per day is typically an active or pregnant/nursing cat. Here's a breakdown of the different calorie needs for cats:\n",
      "\n",
      "**Active Cats**\n",
      "An active adult cat will need about 30 to 35 calories per pound (.45 kg) of body weight per day, and some will do well with about 25 calories per pound per day. An illustration of an active cat playing with a ball of yarn is shown: ![Active cat playing with yarn](IMAGE_PATH_FOR_MD: ./figures/active_cat_yarn.jpg)\n",
      "\n",
      "**Pregnant and Nursing Cats**\n",
      "Pregnant and nursing cats have much higher requirements—figure about 45 calories per pound of body weight per day during the last trimester of pregnancy and as high as 140 calories per pound during the peak of lactation. An image of a pregnant cat with her kittens is shown: ![Pregnant cat with kittens](IMAGE_PATH_FOR_MD: ./figures/pregnant_cat_kittens.jpg)\n",
      "\n",
      "**Spayed/Neutered Cats**\n",
      "Spayed and neutered cats have a much lower metabolism than intact cats. Even if they are active, many spayed and neutered cats do very well on the lower calorie estimate. A picture of a spayed cat is shown: ![Spayed cat](IMAGE_PATH_FOR_MD: ./figures/spayed_cat.jpg)\n",
      "\n",
      "**Senior Cats**\n",
      "Unless maintaining a good body weight is a problem, senior cats should be on a reduced-calorie diet. In general, an older cat who is neither too fat nor too thin needs about 20 calories per pound (.45 kg) of body weight per day—and sometimes even less—to meet her caloric needs. An image of a senior cat is shown: ![Senior cat](IMAGE_PATH_FOR_MD: ./figures/senior_cat.jpg)\n",
      "\n",
      "In summary, cats that need more calories per day are typically active or pregnant/nursing cats. Spayed/Neutered cats may also require more calories, but the exact amount will depend on their individual metabolism and activity level. Senior cats, on the other hand, may require fewer calories to maintain a healthy weight.\n"
     ]
    }
   ],
   "source": [
    "# Your query\n",
    "query = \"What kind of chat need more calories per day? Include images\"\n",
    "\n",
    "# Retrieve documents\n",
    "docs = retriever.invoke(query, limit=6)\n",
    "\n",
    "print(f\"Retrieved {len(docs)} documents:\")\n",
    "\n",
    "# Iterate and display each document\n",
    "for i, doc in enumerate(docs):\n",
    "    doc_content = doc.page_content if isinstance(doc, Document) else str(doc)\n",
    "\n",
    "    print(f\"\\n--- Document {i+1} ---\")\n",
    "    if doc_content.lower().endswith(('.png', '.jpg', '.jpeg')) and os.path.exists(doc_content):\n",
    "        # It's an image path\n",
    "        image_path = doc_content\n",
    "        try:\n",
    "            with open(image_path, 'rb') as f:\n",
    "                image_data = base64.b64encode(f.read()).decode('utf-8')\n",
    "                # Resize for display if needed, using your existing function\n",
    "                # You might want to use a smaller size here for better display in notebook\n",
    "                resized_image_data = resize_base64_image(image_data, size=(600, 300))\n",
    "                plt_img_base64(resized_image_data)\n",
    "                print(f\"Displayed image from: {image_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading or displaying image {image_path}: {e}\")\n",
    "    else:\n",
    "        # It's text or a table summary\n",
    "        print(f\"Text Content:\\n{doc_content}\")\n",
    "\n",
    "print(\"\\n--- LLM Response ---\")\n",
    "# Finally, get the LLM's answer using the chain\n",
    "llm_response = chain_multimodal_rag.invoke(query)\n",
    "print(llm_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The type of cat that needs more calories per day is typically an active or pregnant/nursing cat. Here's a breakdown of the different calorie needs for cats:\n",
       "\n",
       "**Active Cats**\n",
       "An active adult cat will need about 30 to 35 calories per pound (.45 kg) of body weight per day, and some will do well with about 25 calories per pound per day. An illustration of an active cat playing with a ball of yarn is shown: ![Active cat playing with yarn](IMAGE_PATH_FOR_MD: ./figures/active_cat_yarn.jpg)\n",
       "\n",
       "**Pregnant and Nursing Cats**\n",
       "Pregnant and nursing cats have much higher requirements—figure about 45 calories per pound of body weight per day during the last trimester of pregnancy and as high as 140 calories per pound during the peak of lactation. An image of a pregnant cat with her kittens is shown: ![Pregnant cat with kittens](IMAGE_PATH_FOR_MD: ./figures/pregnant_cat_kittens.jpg)\n",
       "\n",
       "**Spayed/Neutered Cats**\n",
       "Spayed and neutered cats have a much lower metabolism than intact cats. Even if they are active, many spayed and neutered cats do very well on the lower calorie estimate. A picture of a spayed cat is shown: ![Spayed cat](IMAGE_PATH_FOR_MD: ./figures/spayed_cat.jpg)\n",
       "\n",
       "**Senior Cats**\n",
       "Unless maintaining a good body weight is a problem, senior cats should be on a reduced-calorie diet. In general, an older cat who is neither too fat nor too thin needs about 20 calories per pound (.45 kg) of body weight per day—and sometimes even less—to meet her caloric needs. An image of a senior cat is shown: ![Senior cat](IMAGE_PATH_FOR_MD: ./figures/senior_cat.jpg)\n",
       "\n",
       "In summary, cats that need more calories per day are typically active or pregnant/nursing cats. Spayed/Neutered cats may also require more calories, but the exact amount will depend on their individual metabolism and activity level. Senior cats, on the other hand, may require fewer calories to maintain a healthy weight."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "# Assuming llm_response contains the string output from your chain\n",
    "# llm_response = chain_multimodal_rag.invoke(query) # Run this to get the response\n",
    "display(Markdown(llm_response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
